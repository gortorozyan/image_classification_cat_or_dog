{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 164,
   "id": "297e8abc-f35c-4f9a-b14a-31706b7adae2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.image as mpimg\n",
    "import cv2\n",
    "from keras import Sequential\n",
    "from keras.layers import Dense, Conv2D, MaxPooling2D, Flatten, Dropout, BatchNormalization\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "id": "0a2bffda-c794-4fe8-98db-34ed33b94f88",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_data_woman = os.listdir('dataset/WOMAN/')\n",
    "y_data_woman = [0 for i in range(len(X_data_woman))]\n",
    "X_data_man = os.listdir('dataset/MEN/')\n",
    "y_data_man = [1 for i in range(len(X_data_man))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "id": "9c04e276-779a-479a-92e5-5541f79b2aa6",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(data=X_data_woman + X_data_man, columns=['Image'])\n",
    "df['Target'] = y_data_woman + y_data_man"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "id": "c9b56479-9601-4a0a-919a-df17d2dc9951",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "id": "a7a91b89-438d-4100-a366-d58caf0452bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df.drop('Target', axis=1)\n",
    "y = df['Target']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "id": "ef49d74a-3608-45dc-befc-cfaf66dada48",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.25, random_state=62)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "id": "32da6492-a789-49cd-8d0e-47104acfd586",
   "metadata": {},
   "outputs": [],
   "source": [
    "mean_size_m = []\n",
    "mean_size_n = []\n",
    "for i in X_data_man:\n",
    "    image = mpimg.imread(f'dataset/MEN/{i}')\n",
    "    mean_size_m.append(image.shape[0])\n",
    "    mean_size_n.append(image.shape[1])\n",
    "for i in X_data_woman:\n",
    "    image = mpimg.imread(f'dataset/WOMAN//{i}')\n",
    "    mean_size_m.append(image.shape[0])\n",
    "    mean_size_n.append(image.shape[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "id": "442a1fed-6dff-4ab1-9cd4-cbdae4f94648",
   "metadata": {},
   "outputs": [],
   "source": [
    "image_size_m = np.mean(mean_size_m)\n",
    "image_size_n = np.mean(mean_size_n)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "id": "35887d3b-7396-4aa3-adfa-674b6cfa865d",
   "metadata": {},
   "outputs": [],
   "source": [
    "image_size_m = int(np.round(image_size_m))\n",
    "image_size_n = int(np.round(image_size_n))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "id": "39e24e36-c3ad-4eb4-a5b3-52ea63cb05c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_data_train = []\n",
    "y_data_train = []\n",
    "for i in range(0, len(X_train['Image'])):\n",
    "    try:\n",
    "        if y_train.iloc[i] == 0:\n",
    "            image = mpimg.imread(f'dataset/WOMAN/{X_train[\"Image\"].iloc[i]}')\n",
    "            image = cv2.resize(image, (image_size_m, image_size_n))\n",
    "            image = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "            image = image.reshape(image_size_m, image_size_n, 1)\n",
    "            if X_train[\"Image\"].iloc[i][-3:] == 'png':\n",
    "                X_data_train.append(image)\n",
    "                y_data_train.append(0)\n",
    "            else:\n",
    "                image = image / 255\n",
    "                X_data_train.append(image)\n",
    "                y_data_train.append(0)\n",
    "                \n",
    "        else:\n",
    "            image = mpimg.imread(f'dataset/MEN/{X_train[\"Image\"].iloc[i]}')\n",
    "            image = cv2.resize(image, (image_size_m, image_size_n))\n",
    "            image = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "            image = image.reshape(image_size_m, image_size_n, 1)\n",
    "            if X_train[\"Image\"].iloc[i][-3:] == 'png':\n",
    "                X_data_train.append(image)\n",
    "                y_data_train.append(1)\n",
    "            else:\n",
    "                image = image / 255\n",
    "                X_data_train.append(image)\n",
    "                y_data_train.append(1)\n",
    "    except:\n",
    "        continue\n",
    "            \n",
    "X_data_train = np.array(X_data_train)\n",
    "y_data_train = np.array(y_data_train)\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "id": "8ed621e8-04f4-4ad3-94f2-499addd0801d",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_data_test = []\n",
    "y_data_test = []\n",
    "for i in range(0, len(X_test['Image'])):\n",
    "    try:\n",
    "        if y_test.iloc[i] == 0:\n",
    "            image = mpimg.imread(f'dataset/WOMAN/{X_test[\"Image\"].iloc[i]}')\n",
    "            image = cv2.resize(image, (image_size_m, image_size_n))\n",
    "            image = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "            image = image.reshape(image_size_m, image_size_n, 1)\n",
    "            if X_test[\"Image\"].iloc[i][-3:] == 'png':\n",
    "                X_data_test.append(image)\n",
    "                y_data_test.append(0)\n",
    "            else:\n",
    "                image = image / 255\n",
    "                X_data_test.append(image)\n",
    "                y_data_test.append(0)\n",
    "                \n",
    "        else:\n",
    "            image = mpimg.imread(f'dataset/MEN/{X_test[\"Image\"].iloc[i]}')\n",
    "            image = cv2.resize(image, (image_size_m, image_size_n))\n",
    "            image = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "            image = image.reshape(image_size_m, image_size_n, 1)\n",
    "            if X_test[\"Image\"].iloc[i][-3:] == 'png':\n",
    "                X_data_test.append(image)\n",
    "                y_data_test.append(1)\n",
    "            else:\n",
    "                image = image / 255\n",
    "                X_data_test.append(image)\n",
    "                y_data_test.append(1)\n",
    "    except:\n",
    "        continue\n",
    "            \n",
    "X_data_test = np.array(X_data_test)\n",
    "y_data_test = np.array(y_data_test)\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "id": "37019bcb-a560-40c2-aa6e-7b209b8b8729",
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.utils import to_categorical"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "id": "2ba8fa14-3a1e-4c62-a55d-dc61d0972e31",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_data_train = to_categorical(y_data_train)\n",
    "y_data_test = to_categorical(y_data_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "id": "37036611-1a84-4b84-89f9-e2a21efa7417",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(969, 2)"
      ]
     },
     "execution_count": 184,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_data_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "id": "e6ab3251-4adb-452b-b384-fb2d20d002de",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(323, 2)"
      ]
     },
     "execution_count": 185,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_data_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "id": "293f4adf-70ad-4f0f-a985-20cd5d052a8b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ASUS\\Desktop\\ML_LOGIX_\\venv\\Lib\\site-packages\\keras\\src\\layers\\convolutional\\base_conv.py:107: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    }
   ],
   "source": [
    "model = Sequential()\n",
    "\n",
    "model.add(Conv2D(filters=32, kernel_size=(3, 3), activation='relu', input_shape=(image_size_m, image_size_n, 1)))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "model.add(Conv2D(filters=64, kernel_size=(3, 3), activation='relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "model.add(Flatten())\n",
    "\n",
    "model.add(Dense(32, activation='relu'))\n",
    "model.add(Dense(16, activation='relu'))\n",
    "model.add(Dense(2, activation='softmax'))\n",
    "\n",
    "\n",
    "model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b3b2f4d-4c6b-41a7-9595-a3f96e127444",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m118s\u001b[0m 4s/step - accuracy: 0.4918 - loss: 2.9564 - val_accuracy: 0.5759 - val_loss: 0.6919\n",
      "Epoch 2/30\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m106s\u001b[0m 3s/step - accuracy: 0.5892 - loss: 0.6740 - val_accuracy: 0.6533 - val_loss: 0.6731\n",
      "Epoch 3/30\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m146s\u001b[0m 4s/step - accuracy: 0.7213 - loss: 0.5869 - val_accuracy: 0.7059 - val_loss: 0.5922\n",
      "Epoch 4/30\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m106s\u001b[0m 3s/step - accuracy: 0.7184 - loss: 0.5512 - val_accuracy: 0.6842 - val_loss: 0.7451\n",
      "Epoch 5/30\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m103s\u001b[0m 3s/step - accuracy: 0.7784 - loss: 0.5012 - val_accuracy: 0.7245 - val_loss: 0.5889\n",
      "Epoch 6/30\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m103s\u001b[0m 3s/step - accuracy: 0.8251 - loss: 0.4280 - val_accuracy: 0.7399 - val_loss: 0.5639\n",
      "Epoch 7/30\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m104s\u001b[0m 3s/step - accuracy: 0.8322 - loss: 0.3941 - val_accuracy: 0.6687 - val_loss: 0.6394\n",
      "Epoch 8/30\n",
      "\u001b[1m15/31\u001b[0m \u001b[32m━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━\u001b[0m \u001b[1m52s\u001b[0m 3s/step - accuracy: 0.8638 - loss: 0.3836"
     ]
    }
   ],
   "source": [
    "model.fit(X_data_train, y_data_train, validation_data=(X_data_test, y_data_test), epochs=30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e76a60c-f128-4fc6-912e-af9b24108b80",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
